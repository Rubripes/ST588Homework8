[
  {
    "objectID": "ST588Homework8.html",
    "href": "ST588Homework8.html",
    "title": "ST588 Homework 8",
    "section": "",
    "text": "##HW 8: Basic Modeling Practice ### First order of business…load libraries that are needed for the project:\nlibrary(readr)\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(gganimate)\nlibrary(tidymodels)\nlibrary(parsnip)"
  },
  {
    "objectID": "ST588Homework8.html#split-the-data",
    "href": "ST588Homework8.html#split-the-data",
    "title": "ST588 Homework 8",
    "section": "Split the Data",
    "text": "Split the Data\nWe’ll split the data into a training and test set (75/25). We’ll use the strata argument to stratify the split on the seasons variable.\nFirst, we’ll use the initial_split(), training(), and testing() functions to create the splits:\n\nset.seed(10)\n#create split with 75% data in training set and 25% in test set, and name the sets\nrental_split &lt;- initial_split(data5, prop = 0.75, strata =\"seasons\")\nrental_train &lt;- training(rental_split)\nrental_test &lt;- testing(rental_split)\nrental_train\n\n# A tibble: 263 × 12\n# Groups:   date, seasons [263]\n   date       seasons holiday    sumCount sumRain sumSnow meanTemp meanHumidity\n   &lt;date&gt;     &lt;fct&gt;   &lt;fct&gt;         &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;\n 1 2018-09-02 Autumn  No Holiday    26881     0         0     25.0         54.5\n 2 2018-09-03 Autumn  No Holiday    10802    34.5       0     23.6         82.2\n 3 2018-09-04 Autumn  No Holiday    29529     0         0     23.3         71.6\n 4 2018-09-07 Autumn  No Holiday    30381     1.5       0     22.2         56.9\n 5 2018-09-08 Autumn  No Holiday    29813     0         0     21.7         48.7\n 6 2018-09-09 Autumn  No Holiday    28354     0         0     22.0         49.5\n 7 2018-09-11 Autumn  No Holiday    31694     0         0     21.6         48.0\n 8 2018-09-13 Autumn  No Holiday    30991     0         0     23.4         62.3\n 9 2018-09-14 Autumn  No Holiday    28199     0.5       0     23.5         67.2\n10 2018-09-15 Autumn  No Holiday    25079     0.2       0     23.2         75.9\n# ℹ 253 more rows\n# ℹ 4 more variables: meanWind &lt;dbl&gt;, meanVis &lt;dbl&gt;, meanDP_C &lt;dbl&gt;,\n#   meanSR &lt;dbl&gt;\n\n\n263/353 = ~ 75%, so that looks like we successfully created the right proportions for our training/test datasets.\n263 rows in the training dataset, which is not evenly divisible by 10. Each fold will have 26 observations, and one fold with have 29.\n\n#calculate fold size by dividing by number of folds (10)\nsize_fold &lt;- floor(nrow(rental_train)/10)\nsize_fold\n\n[1] 26\n\n\nNext, we’ll set a seed and randomly sample the folds into a list.\n\nset.seed(10)\n#randomly create starting indices for each fold\nrandom_indices &lt;- sample(1:nrow(rental_train), size = nrow(rental_train), replace=FALSE)\nhead(random_indices)\n\n[1] 137  72 211 143  24  13\n\n\nWe can see above the first index of each fold.\nNext, we’ll create a list in which to save our folds, then cycle through the random indices vector to place the observations from each fold in the list accordingly.\n\nfolds &lt;- list()\n\nfor(i in 1:10){\n  if (i&lt;10) {\n    fold_index &lt;- seq(from = (i-1)*size_fold + 1, to = i*size_fold, by=1)\n    folds[[i]] &lt;- rental_train[random_indices[fold_index], ]\n  } else {\n    fold_index &lt;- seq(from = (i-1)*size_fold +1, to=length(random_indices), by =1)\n    folds[[i]] &lt;- rental_train[random_indices[fold_index], ]\n  }\n}\n\n#check out the first fold:\nfolds[[1]]\n\n# A tibble: 26 × 12\n# Groups:   date, seasons [26]\n   date       seasons holiday    sumCount sumRain sumSnow meanTemp meanHumidity\n   &lt;date&gt;     &lt;fct&gt;   &lt;fct&gt;         &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;\n 1 2018-06-14 Summer  No Holiday    23818    29       0      21.7          74.4\n 2 2018-03-20 Spring  No Holiday    11515     0       0       5.04         40.6\n 3 2017-12-18 Winter  No Holiday     2620     3.4    59.7    -1.97         77  \n 4 2018-06-22 Summer  No Holiday    34079     0       0      24.7          47.9\n 5 2018-10-08 Autumn  No Holiday    29362     0       0      14.7          46.5\n 6 2018-09-20 Autumn  No Holiday    14282     5       0      19.0          80.2\n 7 2018-05-11 Spring  No Holiday    26649     0       0      15.8          63.5\n 8 2018-09-11 Autumn  No Holiday    31694     0       0      21.6          48.0\n 9 2018-01-12 Winter  No Holiday     4111     0       0     -10.7          36.2\n10 2018-01-13 Winter  No Holiday     3503     0.4     2.2    -4.56         63.8\n# ℹ 16 more rows\n# ℹ 4 more variables: meanWind &lt;dbl&gt;, meanVis &lt;dbl&gt;, meanDP_C &lt;dbl&gt;,\n#   meanSR &lt;dbl&gt;\n\n\nLet’s check out the 10th fold…does it contain 29 observations?\n\nfolds[[10]]\n\n# A tibble: 29 × 12\n# Groups:   date, seasons [29]\n   date       seasons holiday    sumCount sumRain sumSnow meanTemp meanHumidity\n   &lt;date&gt;     &lt;fct&gt;   &lt;fct&gt;         &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;\n 1 2018-03-25 Spring  No Holiday    10963     0         0     9.62         65.8\n 2 2018-07-22 Summer  No Holiday    18563     0         0    31.6          50.9\n 3 2018-04-26 Spring  No Holiday    25670     0         0    15.1          50.1\n 4 2018-09-02 Autumn  No Holiday    26881     0         0    25.0          54.5\n 5 2018-04-23 Spring  No Holiday      977    61         0     9.43         93.8\n 6 2018-05-29 Spring  No Holiday    24355     1         0    21.5          66.4\n 7 2018-03-30 Spring  No Holiday    19301     0         0    14.7          55.0\n 8 2018-06-29 Summer  No Holiday    30297     6.5       0    24.7          79.2\n 9 2018-05-27 Spring  No Holiday    28991     0         0    20.6          42.1\n10 2018-02-11 Winter  No Holiday     2850     0         0    -5.99         40.5\n# ℹ 19 more rows\n# ℹ 4 more variables: meanWind &lt;dbl&gt;, meanVis &lt;dbl&gt;, meanDP_C &lt;dbl&gt;,\n#   meanSR &lt;dbl&gt;\n\n\nYes! There are 29 observations in Fold #10!"
  },
  {
    "objectID": "ST588Homework8.html#fitting-mlr-models",
    "href": "ST588Homework8.html#fitting-mlr-models",
    "title": "ST588 Homework 8",
    "section": "Fitting MLR Models",
    "text": "Fitting MLR Models\nWe’ll create 3 recipes to preprocess the data…\n\nRecipe 1\nWe’ll change the role of date, create a weekday/weekend factor variable from the date, standardize the numberic variables, and create dummy variables for seasons, holiday, and the new variables.\n\nbike_rec1 &lt;- \n  recipe(sumCount ~ ., data=rental_train) %&gt;%\n  #change date to an ID role so that it is not included in fit, but is included in dataset\n  update_role(date, new_role = \"ID\") %&gt;%\n  #change date to day of the week\n  step_mutate(\"date\" = weekdays(date)) %&gt;%\n  #transform day of week into week/weekend factor for inclusion in model fitting\n  step_mutate(\"date\" = factor(if_else(date %in% c(\"Saturday\", \"Sunday\"), \"weekend\", \"weekday\"))) %&gt;%\n  #make all nominal predictors into dummy variables\n  step_dummy(all_nominal_predictors()) %&gt;%\n  #cneter and scale numeric variables, except do not include dummy variables, dates, or outcomes\n  step_normalize(starts_with(c(\"sum\", \"mean\")), -all_date_predictors(), -all_outcomes()) #%&gt;%\n#  prep(training=rental_train) %&gt;%\n#  bake(rental_train)\n\n#bike_rec1\n\nWe’ll next create the same recipe, with interaction terms between seasons and holiday, seasons and temp, and temp and rainfall.\n\nbike_rec2 &lt;- \n  recipe(sumCount ~ ., data=rental_train) %&gt;%\n  update_role(date, new_role = \"ID\") %&gt;%\n  step_mutate(\"date\" = weekdays(date)) %&gt;%\n  step_mutate(\"date\" = factor(if_else(date %in% c(\"Saturday\", \"Sunday\"), \"weekend\", \"weekday\"))) %&gt;%\n  step_dummy(all_nominal_predictors()) %&gt;%\n  step_normalize(starts_with(c(\"sum\", \"mean\")), -all_date_predictors(), -all_outcomes()) %&gt;%\n  step_interact(terms = ~ starts_with(\"seasons\"):starts_with(\"holiday\") + starts_with(\"seasons\"):meanTemp + meanTemp:sumRain) #%&gt;%\n#  prep(training=rental_train) %&gt;%\n#  bake(rental_train)\n\n#bike_rec2\n\nOn to recipe three that includes quadratic terms:\n\nbike_rec3 &lt;- \n  recipe(sumCount ~ ., data=rental_train) %&gt;%\n  update_role(date, new_role = \"ID\") %&gt;%\n  step_mutate(\"date\" = weekdays(date)) %&gt;%\n  step_mutate(\"date\" = factor(if_else(date %in% c(\"Saturday\", \"Sunday\"), \"weekend\", \"weekday\"))) %&gt;%\n  step_dummy(all_nominal_predictors()) %&gt;%\n  step_normalize(starts_with(c(\"sum\", \"mean\")), -all_date_predictors(), -all_outcomes()) %&gt;%\n  step_poly(all_numeric_predictors(), -starts_with(c(\"seasons\", \"holiday\")), degree = 2) #%&gt;%\n#  prep(training=rental_train) %&gt;%\n#  bake(rental_train)\n\n#bike_rec3\n\nNext, we’ll create our model using the lm engine:\n\nrentalMod &lt;- linear_reg() %&gt;%\n  #use \"lm\", or linear model engine for model fitting\n  set_engine(\"lm\")\n\nNext, we’ll create flow to fit the model and out put tidy estimates of the parameters:\n\n#create workflow for recipe 1 that starts with the recipe and fits the preprocessed data through the model engine specified in \"rentalMod\" object.\nrental_wfl_1 &lt;- workflow() %&gt;%\n  add_recipe(bike_rec1) %&gt;%\n  add_model(rentalMod)\n#rental_wfl_1\n\nNext well just fit Recipe 1 to test out our system:\n\n#this code initiates the fitting of the preprocessed data through the model on the training dataset\nrental_fit1 &lt;- rental_wfl_1 %&gt;%\n  fit(rental_train)\nrental_fit1 %&gt;%\n  tidy()\n\n# A tibble: 13 × 5\n   term               estimate std.error statistic  p.value\n   &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)          19423.     1265.    15.3   6.56e-38\n 2 sumRain              -1597.      353.    -4.53  9.24e- 6\n 3 sumSnow               -368.      294.    -1.25  2.12e- 1\n 4 meanTemp             -4793.     4803.    -0.998 3.19e- 1\n 5 meanHumidity         -2939.     1799.    -1.63  1.04e- 1\n 6 meanWind              -626.      315.    -1.99  4.78e- 2\n 7 meanVis               -142.      395.    -0.361 7.19e- 1\n 8 meanDP_C              9880.     5608.     1.76  7.93e- 2\n 9 meanSR                3999.      509.     7.85  1.19e-13\n10 seasons_Spring       -4650.      885.    -5.25  3.18e- 7\n11 seasons_Summer       -3466.     1096.    -3.16  1.75e- 3\n12 seasons_Winter       -8191.     1196.    -6.85  5.85e-11\n13 holiday_No.Holiday    2706.     1196.     2.26  2.45e- 2\n\n\nWe’ll do 10 fold CV on the training data:\n\n#split the training dataset into 10 folds\nrental_10_fold_1 &lt;- vfold_cv(rental_train, 10)\n#resample each of the 10 folds and put the specified workflow\nrental_CV_fits_1 &lt;- rental_wfl_1 %&gt;%\n  fit_resamples(rental_10_fold_1)\nrental_CV_fits_1\n\n# Resampling results\n# 10-fold cross-validation \n# A tibble: 10 × 4\n   splits           id     .metrics         .notes          \n   &lt;list&gt;           &lt;chr&gt;  &lt;list&gt;           &lt;list&gt;          \n 1 &lt;split [236/27]&gt; Fold01 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 2 &lt;split [236/27]&gt; Fold02 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 3 &lt;split [236/27]&gt; Fold03 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 4 &lt;split [237/26]&gt; Fold04 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 5 &lt;split [237/26]&gt; Fold05 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 6 &lt;split [237/26]&gt; Fold06 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 7 &lt;split [237/26]&gt; Fold07 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 8 &lt;split [237/26]&gt; Fold08 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 9 &lt;split [237/26]&gt; Fold09 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n10 &lt;split [237/26]&gt; Fold10 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n\n\nNext we’ll get the metrics:\n\nrental_CV_fits_1 %&gt;%\n  collect_metrics()\n\n# A tibble: 2 × 6\n  .metric .estimator     mean     n  std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   4424.       10 200.     Preprocessor1_Model1\n2 rsq     standard      0.790    10   0.0203 Preprocessor1_Model1\n\n\nNow, we’ll repeat starting from the workflow step for each recipe. First, workflow for recipe 2, fit model, then do 10-fold CV on test dataset, then get metrics for each model:\n\n#create workflow for recipe 2\nrental_wfl_2 &lt;- workflow() %&gt;%\n  add_recipe(bike_rec2) %&gt;%\n  add_model(rentalMod)\nrental_wfl_2\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_mutate()\n• step_mutate()\n• step_dummy()\n• step_normalize()\n• step_interact()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n#create workflow for recipe 3\nrental_wfl_3 &lt;- workflow() %&gt;%\n  add_recipe(bike_rec3) %&gt;%\n  add_model(rentalMod)\nrental_wfl_3\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_mutate()\n• step_mutate()\n• step_dummy()\n• step_normalize()\n• step_poly()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n#fit model 2\nrental_fit2 &lt;- rental_wfl_2 %&gt;%\n  fit(rental_train)\nrental_fit2 %&gt;%\n  tidy()\n\n# A tibble: 20 × 5\n   term                                estimate std.error statistic  p.value\n   &lt;chr&gt;                                  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)                           17269.     1591.    10.9   1.20e-22\n 2 sumRain                               -1794.      346.    -5.18  4.66e- 7\n 3 sumSnow                                -309.      211.    -1.47  1.44e- 1\n 4 meanTemp                              -4462.     3716.    -1.20  2.31e- 1\n 5 meanHumidity                          -3621.     1364.    -2.65  8.46e- 3\n 6 meanWind                               -436.      225.    -1.94  5.41e- 2\n 7 meanVis                                 417.      306.     1.36  1.74e- 1\n 8 meanDP_C                              11065.     4241.     2.61  9.65e- 3\n 9 meanSR                                 2842.      373.     7.62  5.78e-13\n10 seasons_Spring                        -3049.     2837.    -1.07  2.84e- 1\n11 seasons_Summer                        20176.     3153.     6.40  8.03e-10\n12 seasons_Winter                        -5806.     2424.    -2.40  1.74e- 2\n13 holiday_No.Holiday                     4772.     1633.     2.92  3.81e- 3\n14 seasons_Spring_x_holiday_No.Holiday   -1112.     2900.    -0.383 7.02e- 1\n15 seasons_Summer_x_holiday_No.Holiday   -1514.     2747.    -0.551 5.82e- 1\n16 seasons_Winter_x_holiday_No.Holiday   -2271.     2061.    -1.10  2.72e- 1\n17 seasons_Spring_x_meanTemp              5997.     1146.     5.23  3.57e- 7\n18 seasons_Summer_x_meanTemp            -19270.     1520.   -12.7   1.29e-28\n19 seasons_Winter_x_meanTemp              -584.     1458.    -0.401 6.89e- 1\n20 meanTemp_x_sumRain                    -1317.      425.    -3.10  2.18e- 3\n\n#fit model 3\nrental_fit3 &lt;- rental_wfl_3 %&gt;%\n  fit(rental_train)\nrental_fit3 %&gt;%\n  tidy()\n\n# A tibble: 21 × 5\n   term               estimate std.error statistic  p.value\n   &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)          16531.     1269.   13.0    9.46e-30\n 2 seasons_Spring       -4578.      865.   -5.29   2.71e- 7\n 3 seasons_Summer        -160.     1167.   -0.137  8.91e- 1\n 4 seasons_Winter       -4079.     1312.   -3.11   2.10e- 3\n 5 holiday_No.Holiday    3723.     1124.    3.31   1.07e- 3\n 6 sumRain_poly_1      -30478.     6320.   -4.82   2.50e- 6\n 7 sumRain_poly_2        3347.     4445.    0.753  4.52e- 1\n 8 sumSnow_poly_1        -136.     4647.   -0.0293 9.77e- 1\n 9 sumSnow_poly_2       -4268.     4375.   -0.976  3.30e- 1\n10 meanTemp_poly_1    -229695.    89008.   -2.58   1.05e- 2\n# ℹ 11 more rows\n\n#10-fold CV recipe 2\nrental_10_fold_2 &lt;- vfold_cv(rental_train, 10)\nrental_CV_fits_2 &lt;- rental_wfl_2 %&gt;%\n  fit_resamples(rental_10_fold_2)\nrental_CV_fits_2\n\n# Resampling results\n# 10-fold cross-validation \n# A tibble: 10 × 4\n   splits           id     .metrics         .notes          \n   &lt;list&gt;           &lt;chr&gt;  &lt;list&gt;           &lt;list&gt;          \n 1 &lt;split [236/27]&gt; Fold01 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 2 &lt;split [236/27]&gt; Fold02 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 3 &lt;split [236/27]&gt; Fold03 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 4 &lt;split [237/26]&gt; Fold04 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 5 &lt;split [237/26]&gt; Fold05 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 6 &lt;split [237/26]&gt; Fold06 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 7 &lt;split [237/26]&gt; Fold07 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 8 &lt;split [237/26]&gt; Fold08 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 9 &lt;split [237/26]&gt; Fold09 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n10 &lt;split [237/26]&gt; Fold10 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n\n#10-fold CV recipe 3\nrental_10_fold_3 &lt;- vfold_cv(rental_train, 10)\nrental_CV_fits_3 &lt;- rental_wfl_3 %&gt;%\n  fit_resamples(rental_10_fold_3)\nrental_CV_fits_3\n\n# Resampling results\n# 10-fold cross-validation \n# A tibble: 10 × 4\n   splits           id     .metrics         .notes          \n   &lt;list&gt;           &lt;chr&gt;  &lt;list&gt;           &lt;list&gt;          \n 1 &lt;split [236/27]&gt; Fold01 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 2 &lt;split [236/27]&gt; Fold02 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 3 &lt;split [236/27]&gt; Fold03 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 4 &lt;split [237/26]&gt; Fold04 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 5 &lt;split [237/26]&gt; Fold05 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 6 &lt;split [237/26]&gt; Fold06 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 7 &lt;split [237/26]&gt; Fold07 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 8 &lt;split [237/26]&gt; Fold08 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n 9 &lt;split [237/26]&gt; Fold09 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n10 &lt;split [237/26]&gt; Fold10 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;\n\n\nHere, we’ll display the metrics for recipe 2:\n\nrental_CV_fits_2 %&gt;%\n  collect_metrics()\n\n# A tibble: 2 × 6\n  .metric .estimator     mean     n  std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   3236.       10 332.     Preprocessor1_Model1\n2 rsq     standard      0.888    10   0.0283 Preprocessor1_Model1\n\n\n…And for recipe 3:\n\nrental_CV_fits_3 %&gt;%\n  collect_metrics()\n\n# A tibble: 2 × 6\n  .metric .estimator     mean     n  std_err .config             \n  &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard   4290.       10 141.     Preprocessor1_Model1\n2 rsq     standard      0.827    10   0.0112 Preprocessor1_Model1\n\n\nRecipe 2 has the lowest RMSE and highest R-squared.\nWe’ll use the “best” model on the test dataset and see how it fares:\n\n#use last_fit() function to collect metrics from recipe/model 2 and display\ntestResults &lt;- last_fit(rental_wfl_2, split = rental_split)\ncollect_metrics(testResults)\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard    3340.    Preprocessor1_Model1\n2 rsq     standard       0.893 Preprocessor1_Model1\n\n\nRMSE for test dataset is 3339.891 with r-squared of 0.8928. These values seem to match closely to the estimates from the training dataset using recipe 2."
  }
]